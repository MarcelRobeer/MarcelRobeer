### Welkom! üá≥üá±

üêª My name is Marcel Robeer, and I am currently pursuing a [PhD in _Explainable Artificial Intelligence_ (XAI) at Utrecht University](https://uu.nl/staff/MJRobeer)!

---

ü§ñ My thesis projects and scientific research projects have resulted in several open-source Python packages:

- [**Explabox**](https://github.com/MarcelRobeer/explabox): {`Explore` | `Examine` | `Explain` | `Expose` } your AI model with the _explabox_! _JOSS Paper_ [![DOI](https://joss.theoj.org/papers/10.21105/joss.08253/status.svg)](https://doi.org/10.21105/joss.08253).
- [**GlobalCausalAnalysis**](https://github.com/MarcelRobeer/GlobalCausalAnalysis): Explaining Model Behavior with Global Causal Analysis (give a causal overview of how aspects such as task-related features, fairness and robustness relate to black-box model behavior). _xAI 2023 Paper_ [![DOI](https://img.shields.io/badge/10.1007%2F978--3--031--44064-9__17?label=DOI&color=blue)](https://doi.org/10.1007/978-3-031-44064-9_17)
- [**text_explainability**](https://github.com/MarcelRobeer/text_explainability): A generic explainability architecture for explaining text machine learning models.
- [**text_sensitivity**](https://github.com/MarcelRobeer/text_sensitivity): Extension of text_explainability for sensitivity testing (robustness & fairness).
- [**CounterfactualGAN**](https://github.com/marcelrobeer/counterfactualgan): Generating realistic natural language counterfactuals for classifiers and regressors, without requiring explainee intervention. _EMNLP 2021 Paper_.
- [**ContrastiveExplanation**](https://github.com/MarcelRobeer/ContrastiveExplanation): Contrastive and counterfactual explanations for machine learning with Foil Trees. _WHI 2018 Paper_.
- [**VisualNarrator**](https://github.com/MarcelRobeer/VisualNarrator): Turns user stories into a conceptual model containing entities and relationships. _RE 2016 Paper_.

---

üíª Check out [marcelrobeer.github.io](https://marcelrobeer.github.io) for a full overview. See you there!
